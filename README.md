# LAB_-Artificial_intelligence_principles_and_methods_Prykhodko_Bohdan_IT

**Предмет:** Штучний інтелект: принципи та методи  
**Викладач:** Марченко Олександр Олександрович — професор, гарант ОНП “Інтелектуальні системи”

## Постановка задачі

Метою роботи є створення системи автоматичного визначення фішингових електронних листів на основі їхнього текстового вмісту. Система повинна класифікувати повідомлення як «фішингове» або «легітимне», використовуючи методи машинного навчання та глибинних нейронних мереж.

### Вхідні дані
- Текст електронного листа (тіло повідомлення)
- Опціонально: метадані (тема листа, посилання, присутність підозрілих патернів)

Формат:
email_body → string

### Вихідні дані
- Двокласовий результат класифікації:
  - 1 — Фішингове повідомлення
  - 0 — Легітимне повідомлення
- Ймовірність належності до класу (confidence score)

Формат:
label ∈ {0, 1}, confidence ∈ [0, 1]


### Метрики оцінки якості
- Accuracy
- Precision
- Recall
- F1-score

### Моделі для порівняння
Для оцінки впливу складності моделі на результативність класифікації застосовуються три підходи:

| Рівень | Модель | Опис |
|-------|--------|------|
| Проста | Logistic Regression | Базова модель з TF-IDF ознаками |
| Середня | Text CNN | Згорткова нейромережа для аналізу тексту |
| Складна | BERT Transformer | Державний стандарт NLP для глибокого семантичного аналізу тексту |

### Очікувані результати
- Порівняння ефективності трьох підходів на спільному датасеті
- Визначення моделі, що найкраще виявляє фішингові листи в умовах реального середовища

## Опис датасету

У дослідженні використовується датасет текстів електронних листів для задачі виявлення фішингових повідомлень. Дані містять вміст листа та позначку його типу.

### Структура датасету

| Назва колонки | Тип | Опис |
|---------------|-----|------|
| `body` | string | Текстовий вміст електронного листа |
| `label` | int (0/1) | Клас повідомлення: 0 — легітимне, 1 — фішингове |

### Розмір вибірки
- **Загальна кількість записів:** 19 489
- **Кількість фішингових листів (label = 1):** 10 590  
- **Кількість легітимних листів (label = 0):** 8 899  

Дані є **збалансованими з невеликим домінуванням фішингових повідомлень**, що не потребує складних технік балансування класів.

### Джерело та зміст
Тексти повідомлень включають характерні ознаки фішингу:
- вимоги термінової дії
- посилання на сумнівні ресурси
- загрози щодо блокування акаунту
- спроби викрадення персональних даних

Легітимні повідомлення містять загальний інформативний контент: робоче листування, нагадування, повідомлення про доставку тощо.

### Попередня обробка
- очищення від HTML тегів і сміттєвих символів
- нормалізація пробілів
- стандартизація форматів тексту
- у GUI передбачено переклад українського тексту ➜ англійською
- для моделей CNN/BERT використовується розбиття довгих текстів на **чанки**

## Структура репозиторію

```text
Project_AI_Phishing_Detector/
├── data/
│   └── phishing_dataset_bert.csv
│
├── models/
│   ├── logreg_model/
│   │   ├── model.pkl
│   │   └── tfidf.pkl
│   │
│   ├── cnn_model/
│   │   ├── model.h5
│   │   └── tokenizer.pkl
│   │
│   └── bert_model/
│       ├── config.json
│       ├── tokenizer.json
│       └── pytorch_model.bin
│
├── src/
│   ├── logistic_regression.py
│   ├── CNN.py
│   ├── bert.py
│   └── gui.py
│
├── metrics/
│   ├── logreg_metrics.json
│   ├── cnn_metrics.json
│   └── bert_metrics.json
│
├── docs/
│   └── AI_prez_prykhodko.pdf
│
├── README.md
└── .gitignore
```
## Реалізація модулів

src/logistic_regression.py — реалізація базового класифікатора Logistic Regression на TF-IDF ознаках.

src/CNN.py — реалізація згорткової нейромережі для текстової класифікації (Text CNN).

src/bert.py — використання попередньо натренованої моделі BERT для класифікації листів.

src/gui.py — графічний інтерфейс користувача (CustomTkinter):
• можливість введення тексту та аналізу в один клік  
• підтримка української мови (автоматичний переклад ➜ англійською)  
• обробка довгих листів через розбиття на чанки  

metrics/*.json — збережені метрики якості для порівняння моделей.

docs/AI_prez_prykhodko.pdf — презентація до проєкту.

## Встановлення

Створити та активувати віртуальне середовище:

### Windows:
```bash
python -m venv .venv
.venv\Scripts\activate
```
Linux / macOS:
```bash
python3 -m venv .venv
source .venv/bin/activate
```
Встановити залежності:
```bash
pip install -r requirements.txt
```
Logistic Regression:
```bash
python src/logistic_regression.py
```
Text CNN:
```bash
python src/CNN.py
```
BERT:
```bash
python src/bert.py
```
Запуск GUI:
```bash
python src/gui.py
```
## Хід роботи

- Виконано попередню обробку текстів:
  • видалення HTML-структур, тегів і службових символів  
  • нормалізація пробілів та приведення тексту до стандартного вигляду  
  • усунення некоректних символів і посилань  
  • поділ датасету на train/validation/test зі збереженням пропорції класів  

- Розроблено три моделі машинного навчання різної складності:

  • **Logistic Regression (Baseline модель)**  
    - текст перетворений у векторне представлення методом TF-IDF (уніграм і біграм ознаки)  
    - налаштовані гіперпараметри: регуляризація, max_iter  
    - проведено навчання та тестування на однакових вибірках  
    - модель забезпечує швидку роботу та служить відправною точкою для порівняння

  • **Text CNN (нейромережева модель середнього рівня)**  
    - використано Tokenizer + Embedding шар для перетворення слів у щільні вектори  
    - застосовано згорткові фільтри (Conv1D) для виявлення шаблонів у фразах  
    - GlobalMaxPooling1D для виділення найважливіших ознак  
    - додано Dropout для зменшення перенавчання  
    - оптимізовано кількість епох і batch size  
    - модель краще розпізнає структуру та контекст порівняно з класичними методами

  • **BERT Transformer (високопродуктивна модель)**  
    - використано попередньо натреновану трансформерну модель для класифікації тексту  
    - fine-tuning на спеціалізованому датасеті фішингових листів  
    - токенізація за WordPiece, підтримка глибокого контекстного аналізу  
    - реалізовано розбиття довгих листів на чанки для збереження максимальної інформативності  
    - об'єднання результатів усіх чанків через усереднення ймовірностей  
    - модель демонструє найвищу точність і є готовою до реального застосування

- Для кожної моделі виконано оцінку якості:
  • Accuracy, Precision, Recall, F1-score  
  • метрики збережено у форматі JSON для подальшого порівняння
  
## Результати 

| Модель              | Accuracy | Precision | Recall | F1-score |
| ------------------- | :------: | :-------: | :----: | :------: |
| Logistic Regression |  0.9836  |   0.9750  | 0.9953 |  0.9850  |
| Text CNN            |  0.9785  |   0.9652  | 0.9962 |  0.9805  |
| BERT Transformer    |  0.9985  |   0.9991  | 0.9981 |  0.9986  |

• BERT показує найвищу точність та F1-score — модель добре узагальнює дані, мінімально помиляється при розпізнаванні фішингу;

• Logistic Regression і CNN демонструють високі результати, але поступаються трансформеру у стабільності прогнозів;

Усі моделі правильно розпізнають фішинг — але:
| Модель               | Confidence (приблизно по прикладу) |
| -------------------- | :--------------------------------: |
| Logistic Regression  |                ~91%                |
| Text CNN             |                ~98%                |
| **BERT Transformer** |                ~99%                |

<img width="1085" height="742" alt="image" src="https://github.com/user-attachments/assets/5ef79cdd-4148-4722-b2e8-24093232b28c" />
<img width="1108" height="757" alt="image" src="https://github.com/user-attachments/assets/eceb00d7-2c33-41a5-bb3e-323e57b7e592" />
<img width="1097" height="754" alt="image" src="https://github.com/user-attachments/assets/069cdbf1-bc25-4e50-9dbe-3fe039ea27ba" />
<img width="1098" height="736" alt="image" src="https://github.com/user-attachments/assets/b9674c99-88cb-4bc9-9689-8bf85ffc998b" />
<img width="1119" height="762" alt="image" src="https://github.com/user-attachments/assets/ba538a53-fd97-4009-a288-92040b7e3763" />
<img width="1108" height="759" alt="image" src="https://github.com/user-attachments/assets/5f0510b0-49fc-43bd-8108-951e8aac4892" />

## Висновки 
Система успішно визначає фішингові листи за текстом повідомлення. Серед трьох протестованих моделей найкращий результат показав BERT, Text CNN забезпечив хорошу якість при меншій складності, а Logistic Regression підходить як базове швидке рішення. Створений графічний інтерфейс дає можливість легко перевіряти підозрений текст і отримувати результат у реальному часі.






